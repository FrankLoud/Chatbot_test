{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick but complete test of Seq2seq Chatbot\n",
    "\n",
    "## Part 1: Basic Seq2seq\n",
    "\n",
    "This is the first part of my Chatbot test. I'll look into the performance of some famous deep learning methods for NLP tesk. Thus, I adopt the quickest implement of Seq2seq Chatbot by Tensorflow's new rnn API. Hope you and me will get some insight into the behaviour and the capability of Seq2seq after completing the notebook.\n",
    "\n",
    "Prerequisits(only recommend):\n",
    "\n",
    "- python 3.5 or 3.6\n",
    "\n",
    "- tensorflow 1.4.0 (cpu)\n",
    "\n",
    "- Tensorflow's new Seq2seq API tutorial: https://www.tensorflow.org/tutorials/seq2seq\n",
    "\n",
    "- (optinal)A Tensorflow's legacy_seq2seq Chatbot: https://github.com/nicolas-ivanov/tf_seq2seq_chatbot  \n",
    "(Tensorflow's legacy_seq2seq is not as flexiable as Tensorflow's new Seq2seq, but it's more fundamental.)\n",
    "\n",
    "- CS224n or other deep learning in NLP course.\n",
    "(Because this notebook has few theoretical instruction)\n",
    "\n",
    "If you are Chinese, you are recommended to read a better instruction at zhihu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ignore warnings for better demonstration\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Make tensorflow less verbose; filter out info (1+) and warnings (2+) but not errors (3).\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "from six.moves import xrange\n",
    "print(tf.__version__)\n",
    "\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set seed\n",
    "SEED = 0\n",
    "tf.set_random_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "#set config\n",
    "class gen_config(object):\n",
    "    initialize = True\n",
    "    learning_rate = 0.5\n",
    "    learning_rate_decay_factor = 0.99\n",
    "    batch_size = 128\n",
    "    emb_dim = 128 # 512\n",
    "    num_layers = 1 # 2\n",
    "    vocab_size = 20000\n",
    "    max_gradient_norm = 5.0\n",
    "    steps_per_checkpoint = 200\n",
    "    pretrain_steps = 4000\n",
    "    train_dir = 'data' # 'movie_data'\n",
    "    save_dir = 'log/gen_models' #'log/movie_gen_models'\n",
    "    tensorboard_dir = 'log/tensorboard'\n",
    "    buckets = [(5, 10), (10, 15), (20, 25), (40, 50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "I use the DailyDialog from http://yanran.li/dailydialog\n",
    "> Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset. IJCNLP 2017.\n",
    "\n",
    "I will also test the Cornell Movie-Dialogs Corpus http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
    "> \"Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs\"\n",
    "Cristian Danescu-Niculescu-Mizil and Lillian Lee\n",
    "Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics, ACL 2011.\n",
    "\n",
    "I have check the OpenSubtitles and Reddit comments(https://github.com/julien-c/chatbot-rnn), but those corpus are more large and noisy.\n",
    "\n",
    "data_utils.py deal with the training and test data. You can look into data_utils.py for detailed instruction of data processing.\n",
    "In short, data_utils.prepare_data will create vocabularies, tokenize data, and return vocab, rev_vocab, dev_set, train_set:\n",
    "\n",
    "dev_set or train_set: a list of length len(buckets); data_set[n] contains a list of\n",
    "      (source, target) pairs read from the provided data files that fit into the n-th bucket\n",
    "\n",
    "You can have a look at a few train data during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocabulary data/vocab20000.in from data data/chat.in\n",
      "  processing line 100000\n",
      "Tokenizing data in data/chat.in\n",
      "  tokenizing line 10000\n",
      "  quary:  What time ?\n",
      "   answer:  At 8 o'clock . I will make the reservation .\n",
      "\n",
      "  tokenizing line 20000\n",
      "  quary:  Ok . Can I ask who is calling , please ?\n",
      "   answer:  This is Nathaniel Brown .\n",
      "\n",
      "  tokenizing line 30000\n",
      "  quary:  I usually take the 5 thirty home .\n",
      "   answer:  And can you get a seat ?\n",
      "\n",
      "  tokenizing line 40000\n",
      "  quary:  Can you tell me something about the Spring Festival ?\n",
      "   answer:  Just like you celebrate Christmas , we celebrate our lunar New Year's Day , the Spring Festival . It is a time for the family members and relatives to have a get-together .\n",
      "\n",
      "  tokenizing line 50000\n",
      "  quary:  That's a cool jacket . Where did you get it ?\n",
      "   answer:  I bought it when I was on vacation in Nepal .\n",
      "\n",
      "  tokenizing line 60000\n",
      "  quary:  You've got to be joking .\n",
      "   answer:  No , I'm not .\n",
      "\n",
      "  tokenizing line 70000\n",
      "  quary:  Don ’ t tell me ! I ’ m sure it ’ s someplace warm and sunny with great beaches !\n",
      "   answer:  You got it ! I ’ m going to spend two fabulous weeks in Hawaii !\n",
      "\n",
      "  tokenizing line 80000\n",
      "  quary:  It can't be that bad .\n",
      "   answer:  I wish it wasn't , but there is actually a lot of crime and prostitution around here .\n",
      "\n",
      "  tokenizing line 90000\n",
      "  quary:  I'm very busy these days . It seems I can never finish my work .\n",
      "   answer:  Well , take it easy ! Don't let it get on top of you .\n",
      "\n",
      "  tokenizing line 100000\n",
      "  quary:  You don't sound too excited about going to your reunion .\n",
      "   answer:  I'm not . I get a stomachache just thinking about it .\n",
      "\n",
      "  tokenizing line 110000\n",
      "  quary:  This is Ryan . How may I help you ?\n",
      "   answer:  Ryan , this is Malia , and I am afraid that I am feeling a bit under the weather .\n",
      "\n",
      "  tokenizing line 120000\n",
      "  quary:  Do you have a lot on your mind when you try to go to sleep ?\n",
      "   answer:  My mother is ill with cancer , and I think about her a lot .\n",
      "\n",
      "  tokenizing line 130000\n",
      "  quary:  I'd like to see it for myself .\n",
      "   answer:  Go right ahead .\n",
      "\n",
      "  tokenizing line 140000\n",
      "  quary:  Yes , of course . When you hear the fire alarm , which is a very loud , continuous ringing noise , you should go to the nearest fire exit or fire escape as quickly as possible .\n",
      "   answer:  Should we use the stairs ?\n",
      "\n",
      "  tokenizing line 150000\n",
      "  quary:  No . I'd like to do something special for you on your birthday .\n",
      "   answer:  I'd like that . Alright , put on this apron first .\n",
      "\n",
      "Tokenizing data in data/chat_test.in\n",
      "  tokenizing line 10000\n",
      "  quary:  Really ?\n",
      "   answer:  But I think Henry is a backroom boy.He always helps her with her study .\n",
      "\n",
      "Reading development and training gen_data\n"
     ]
    }
   ],
   "source": [
    "#prepare the data\n",
    "vocab, rev_vocab, dev_set, train_set = data_utils.prepare_data(gen_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "I only build the basic seq2seq in this notebook(only one layer, without attention). In the next notebook, I will test more advance model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build Craph\n",
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, name_scope, forward_only=False, num_samples=512, dtype=tf.float32):\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.emb_dim = config.emb_dim\n",
    "        self.buckets = config.buckets\n",
    "        self.learning_rate = tf.Variable(float(config.learning_rate), name=\"learning_rate\", \n",
    "                                         trainable=False, dtype=dtype)\n",
    "        self.learning_rate_decay_op = self.learning_rate.assign(\n",
    "                                        self.learning_rate * config.learning_rate_decay_factor)\n",
    "        self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        self.batch_size = config.batch_size\n",
    "        self.num_layers = config.num_layers\n",
    "        self.max_gradient_norm = config.max_gradient_norm\n",
    "        self.forward_only = tf.placeholder(tf.bool, name=\"forward_only\")\n",
    "        # Feeds for inputs. shape: [seq_len, batch]\n",
    "        self.encoder_inputs = tf.placeholder(tf.int32, shape=[None, None], name=\"encoder_inputs\")\n",
    "        self.decoder_inputs = tf.placeholder(tf.int32, shape=[None, None], name=\"decoder_inputs\")\n",
    "        self.targets = tf.placeholder(tf.int32, shape=[None, None], name=\"targets\")\n",
    "        self.target_weights = tf.placeholder(tf.float32, shape=[None, None], name=\"target_weight\")\n",
    "        self.inputs_len = tf.placeholder(tf.int32, shape=[None])\n",
    "        self.target_len = tf.placeholder(tf.int32, shape=[None])\n",
    "        size = self.emb_dim\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_embedding = tf.get_variable(\n",
    "                \"encoder_embedding\", [self.vocab_size, self.emb_dim], dtype=tf.float32)\n",
    "        embed_inputs = tf.nn.embedding_lookup(self.enc_embedding, self.encoder_inputs)\n",
    "            # shape: [seq_len, batch, emb_dim]\n",
    "        # Encoder\n",
    "        encoder_cell = tf.nn.rnn_cell.GRUCell(size)\n",
    "        if self.num_layers > 1:\n",
    "            encoder_cell = tf.nn.rnn_cell.MultiRNNCell([encoder_cell] * self.num_layers)\n",
    "        # Dynamic encoding\n",
    "        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "            encoder_cell, embed_inputs, dtype=tf.float32, \n",
    "            sequence_length=self.inputs_len, time_major=True)\n",
    "        \n",
    "        # Output projection layer\n",
    "        with tf.variable_scope(\"output_projection\"):\n",
    "            self.output_layer = tf.layers.Dense(self.vocab_size)\n",
    "            self.output_layer.build(size)\n",
    "            # w and b are used in sample_loss\n",
    "            w = self.output_layer.kernel\n",
    "            w_t = tf.transpose(w)\n",
    "            b = self.output_layer.bias\n",
    "\n",
    "        # Decoder\n",
    "        # we use the same embedding as encoder's.\n",
    "        embed_targets = tf.nn.embedding_lookup(self.enc_embedding, self.decoder_inputs)\n",
    "        decoder_cell = tf.nn.rnn_cell.GRUCell(size)\n",
    "        if self.num_layers > 1:\n",
    "            decoder_cell = tf.nn.rnn_cell.MultiRNNCell([decoder_cell] * self.num_layers)\n",
    "        if not forward_only:\n",
    "            # teacher focusing\n",
    "            helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                embed_targets, self.target_len, time_major=True)\n",
    "        else:\n",
    "            start_tokens = tf.fill([self.batch_size], data_utils.GO_ID)\n",
    "            end_token = -1 \n",
    "            # we dont need EOS to finish decoding(for compating with the shape of self.targets)\n",
    "            helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                self.enc_embedding, start_tokens, end_token)\n",
    "        # creat decoder\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper, encoder_state, \n",
    "            output_layer=None if not forward_only else self.output_layer)\n",
    "\n",
    "        # Dynamic decoding\n",
    "        outputs, final_context_state, final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder,\n",
    "            maximum_iterations=None if not forward_only else tf.reduce_max(self.target_len),\n",
    "            output_time_major=True,\n",
    "            swap_memory=True)\n",
    "        self.sample_id = outputs.sample_id\n",
    "        self.logits = outputs.rnn_output\n",
    "        \n",
    "        # Loss\n",
    "        # we use sampled_loss to speed up.\n",
    "        def sampled_loss(labels, logits):\n",
    "            labels = tf.reshape(labels, [-1, 1])\n",
    "            return tf.cast(\n",
    "                tf.nn.sampled_softmax_loss(weights=w_t, biases=b, inputs=logits, labels=labels,\n",
    "                                    num_sampled=num_samples, num_classes=self.vocab_size), dtype)\n",
    "        if not forward_only:\n",
    "            # compute the sequence loss with sampled_loss, and only average across batch.\n",
    "            self.loss = tf.contrib.seq2seq.sequence_loss(logits=self.logits, targets=self.targets, \n",
    "                                                         weights=self.target_weights,\n",
    "                                                        average_across_timesteps=False,\n",
    "                                                        average_across_batch=False,\n",
    "                                                        softmax_loss_function=sampled_loss)\n",
    "            self.loss = tf.reduce_sum(self.loss) / tf.to_float(self.batch_size)\n",
    "            \n",
    "        else:\n",
    "            # at test time, we don't use sampled_loss.\n",
    "            crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels=self.targets, logits=self.logits)\n",
    "            self.loss = tf.reduce_sum(crossent * self.target_weights)/tf.to_float(self.batch_size)\n",
    "            \n",
    "        # Gradient Descent\n",
    "        params = tf.trainable_variables()\n",
    "        if not forward_only:\n",
    "            opt = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "            gradients = tf.gradients(self.loss, params)\n",
    "            clipped_gradients, norm = tf.clip_by_global_norm(gradients, self.max_gradient_norm)\n",
    "            self.gradient_norm=norm\n",
    "            self.update=opt.apply_gradients(zip(clipped_gradients, params), \n",
    "                                            global_step=self.global_step)\n",
    "\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "    # train the model or test the model for one batch.\n",
    "    def step(self, session, encoder_inputs, decoder_inputs, target_weights, \n",
    "             inputs_len, target_len, bucket_id, forward_only):\n",
    "        \n",
    "        encoder_size, decoder_size = self.buckets[bucket_id]\n",
    "        # Input feed: encoder inputs, decoder inputs, target_weights, as provided.\n",
    "        input_feed = {}\n",
    "        input_feed[self.encoder_inputs] = encoder_inputs\n",
    "        input_feed[self.decoder_inputs] = decoder_inputs\n",
    "        input_feed[self.target_weights] = target_weights\n",
    "        # Our targets are decoder inputs shifted by one.\n",
    "        input_feed[self.targets] = decoder_inputs[1:]+[np.zeros([self.batch_size],dtype=np.int32)]\n",
    "\n",
    "        input_feed[self.inputs_len] = inputs_len\n",
    "        input_feed[self.target_len] = np.ones([self.batch_size], dtype=np.int32)* decoder_size\n",
    "        # Output feed: depends on whether we do a backward step or not.\n",
    "        if not forward_only:\n",
    "            output_feed = [self.update,  # Update Op that does SGD.\n",
    "                         self.gradient_norm,  # Gradient norm.\n",
    "                         self.loss]  # Loss for this batch.\n",
    "        else:\n",
    "            output_feed = [self.loss]  # Loss for this batch.\n",
    "            for l in xrange(decoder_size if decoder_size<20 else 20):  # Output logits.\n",
    "                output_feed.append(self.sample_id[l])\n",
    "\n",
    "        outputs = session.run(output_feed, input_feed)\n",
    "        if not forward_only:\n",
    "            return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.\n",
    "        else:\n",
    "            return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(gen_config):\n",
    "    # creating and loading the vocabulary and the train and dev data\n",
    "    vocab, rev_vocab, dev_set, train_set = data_utils.prepare_data(gen_config)\n",
    "    for b_set in train_set:\n",
    "        print(\"b_set: \", len(b_set))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print(\"Creating %d layers of %d units.\" % (gen_config.num_layers, gen_config.emb_dim))\n",
    "        creat_time = time.time()\n",
    "        model = Seq2SeqModel(gen_config, name_scope=\"Basic_Seq2seq\", forward_only=False,\n",
    "                                        dtype=tf.float32)\n",
    "        sess.run(tf.variables_initializer(tf.global_variables()))\n",
    "        print(\"creat gen_model time: %.3f\" % (time.time()-creat_time))\n",
    "\n",
    "        # This is the training loop.\n",
    "        step_time, loss = 0.0, 0.0\n",
    "        current_step = 0\n",
    "        previous_losses = []\n",
    "        log_data = {'t':[], 'loss':[]}\n",
    "        \n",
    "        bucket_sizes=[len(train_set[b]) for b in range(len(gen_config.buckets))]\n",
    "        \n",
    "        print(\"Begin training...\")\n",
    "        print(\"Record every %d steps\" % gen_config.steps_per_checkpoint)\n",
    "        while current_step < gen_config.pretrain_steps:\n",
    "            # Choose a bucket according to data distribution.\n",
    "            bucket_id = data_utils.get_bucket_id(gen_config, bucket_sizes)\n",
    "\n",
    "            # Get a batch and make a step.\n",
    "            start_time = time.time()\n",
    "            encoder_inputs, decoder_inputs, target_weights, inputs_len, target_len = \\\n",
    "                    data_utils.get_batch(gen_config, train_set, bucket_id)\n",
    "\n",
    "            _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, \n",
    "                                         inputs_len, target_len, bucket_id, forward_only=False)\n",
    "\n",
    "            step_time += (time.time() - start_time) / gen_config.steps_per_checkpoint\n",
    "            loss += step_loss / gen_config.steps_per_checkpoint\n",
    "            current_step += 1\n",
    "            print(\"\\r step:{:5}  step_loss:{:8.4f} step_time:{:8.4f} bucket:{}\".format(\n",
    "                current_step, step_loss, time.time() - start_time, bucket_id), end=' ')\n",
    "            # Once in a while, we print statistics.\n",
    "            if current_step % gen_config.steps_per_checkpoint == 0:\n",
    "                # Print statistics for the previous epoch.\n",
    "                perplexity = math.exp(loss) if loss < 300 else float('inf')\n",
    "                print(\"\\n global step %d learning rate %.4f step-time %.2f loss %.4f perplexity \"\n",
    "                      \"%.2e\" % (model.global_step.eval(), model.learning_rate.eval(),\n",
    "                                step_time, loss, perplexity))\n",
    "                # Decrease learning rate if no improvement was seen over last 3 times.\n",
    "                if len(previous_losses) > 2 and loss > max(previous_losses[-3:]):\n",
    "                    sess.run(model.learning_rate_decay_op)\n",
    "                previous_losses.append(loss)\n",
    "                log_data['t'].append(current_step)\n",
    "                log_data['loss'].append(loss)\n",
    "                step_time, loss = 0.0, 0.0\n",
    "                sys.stdout.flush()\n",
    "        # Save model\n",
    "        gen_ckpt_dir = os.path.abspath(os.path.join(gen_config.save_dir, \"checkpoints\"))\n",
    "        if gfile.Exists(gen_ckpt_dir):\n",
    "            gfile.DeleteRecursively(gen_ckpt_dir)\n",
    "        gfile.MakeDirs(gen_ckpt_dir)\n",
    "        checkpoint_path = os.path.join(gen_ckpt_dir, \"gen.model\")\n",
    "        print(\"current_step: %d, save model to %s\" % (current_step, \n",
    "                            os.path.join(gen_config.save_dir, \"checkpoints\")))\n",
    "        model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n",
    "        return log_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Let's begin training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading development and training gen_data\n",
      "b_set:  1785\n",
      "b_set:  16959\n",
      "b_set:  33353\n",
      "b_set:  20381\n",
      "Creating 1 layers of 128 units.\n",
      "creat gen_model time: 1.207\n",
      "Begin training...\n",
      "Record every 200 steps\n",
      " step:  200  step_loss: 59.0128 step_time:  0.2088 bucket:2 \n",
      " global step 200 learning rate 0.5000 step-time 0.19 loss 81.8201 perplexity 3.42e+35\n",
      " step:  400  step_loss: 31.2742 step_time:  0.0935 bucket:1  \n",
      " global step 400 learning rate 0.5000 step-time 0.20 loss 62.8486 perplexity 1.97e+27\n",
      " step:  600  step_loss: 86.7572 step_time:  0.2348 bucket:3   \n",
      " global step 600 learning rate 0.5000 step-time 0.19 loss 55.9051 perplexity 1.90e+24\n",
      " step:  800  step_loss: 43.6771 step_time:  0.1829 bucket:2 \n",
      " global step 800 learning rate 0.5000 step-time 0.19 loss 52.1704 perplexity 4.54e+22\n",
      " step: 1000  step_loss: 45.3504 step_time:  0.2258 bucket:2 \n",
      " global step 1000 learning rate 0.5000 step-time 0.20 loss 53.7342 perplexity 2.17e+23\n",
      " step: 1200  step_loss: 42.0338 step_time:  0.1213 bucket:2  \n",
      " global step 1200 learning rate 0.5000 step-time 0.19 loss 49.7335 perplexity 3.97e+21\n",
      " step: 1400  step_loss: 82.3244 step_time:  0.3644 bucket:3  \n",
      " global step 1400 learning rate 0.5000 step-time 0.21 loss 52.0533 perplexity 4.04e+22\n",
      " step: 1600  step_loss: 27.1018 step_time:  0.1008 bucket:1 \n",
      " global step 1600 learning rate 0.5000 step-time 0.20 loss 49.4393 perplexity 2.96e+21\n",
      " step: 1800  step_loss: 40.4441 step_time:  0.2228 bucket:2 \n",
      " global step 1800 learning rate 0.5000 step-time 0.18 loss 47.8799 perplexity 6.22e+20\n",
      " step: 2000  step_loss: 42.0238 step_time:  0.1753 bucket:2  \n",
      " global step 2000 learning rate 0.5000 step-time 0.19 loss 46.1180 perplexity 1.07e+20\n",
      " step: 2200  step_loss: 21.1600 step_time:  0.1219 bucket:1  \n",
      " global step 2200 learning rate 0.5000 step-time 0.20 loss 45.0652 perplexity 3.73e+19\n",
      " step: 2400  step_loss: 38.4520 step_time:  0.1560 bucket:2   \n",
      " global step 2400 learning rate 0.5000 step-time 0.20 loss 45.2263 perplexity 4.38e+19\n",
      " step: 2600  step_loss: 38.8093 step_time:  0.1468 bucket:2 \n",
      " global step 2600 learning rate 0.5000 step-time 0.20 loss 45.1872 perplexity 4.21e+19\n",
      " step: 2800  step_loss: 36.5381 step_time:  0.1703 bucket:2  \n",
      " global step 2800 learning rate 0.5000 step-time 0.20 loss 43.5901 perplexity 8.53e+18\n",
      " step: 3000  step_loss: 36.6104 step_time:  0.1606 bucket:2 \n",
      " global step 3000 learning rate 0.5000 step-time 0.20 loss 44.2326 perplexity 1.62e+19\n",
      " step: 3200  step_loss: 35.4241 step_time:  0.2247 bucket:2  \n",
      " global step 3200 learning rate 0.5000 step-time 0.20 loss 42.7334 perplexity 3.62e+18\n",
      " step: 3400  step_loss: 71.0401 step_time:  0.3446 bucket:3    \n",
      " global step 3400 learning rate 0.5000 step-time 0.20 loss 43.8326 perplexity 1.09e+19\n",
      " step: 3600  step_loss: 37.9776 step_time:  0.2116 bucket:2 \n",
      " global step 3600 learning rate 0.5000 step-time 0.19 loss 41.0288 perplexity 6.59e+17\n",
      " step: 3800  step_loss: 22.7297 step_time:  0.0778 bucket:1     \n",
      " global step 3800 learning rate 0.5000 step-time 0.19 loss 40.5447 perplexity 4.06e+17\n",
      " step: 4000  step_loss: 38.6342 step_time:  0.1800 bucket:2    \n",
      " global step 4000 learning rate 0.5000 step-time 0.18 loss 37.8873 perplexity 2.85e+16\n",
      "current_step: 4000, save model to log/gen_models/checkpoints\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    log_data = train(gen_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training result seems not bad. Let's plot the training process for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEjCAYAAAA/ugbCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY0KcJQJjjAlx/w/t8vANsO7oVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff69048af28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "log_t = log_data['t']\n",
    "log_loss = log_data['loss']\n",
    "log_plot= plt.figure()\n",
    "plt.plot(log_t, log_loss, label='teacher focusing loss')\n",
    "plt.suptitle('Basic Seq2seq Training Loss', fontsize=20)\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "plt.ylabel('MLE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "we use MLE loss and BLEU score(http://aclweb.org/anthology/P/P02/P02-1040.pdf) to evaluate.\n",
    "\n",
    "At training time, the decode mode is teacher focusing, while at test time, the decode mode is free running. Thus, the MLE loss is supposed to be much higher than it at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bleu\n",
    "def eval(gen_config):\n",
    "    vocab, rev_vocab, dev_set, train_set = data_utils.prepare_data(gen_config)\n",
    "    for b_set in dev_set:\n",
    "        print(\"b_set: \", len(b_set))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        model = Seq2SeqModel(gen_config, name_scope=\"Basic_Seq2seq\", forward_only=True,\n",
    "                                            dtype=tf.float32)\n",
    "        gen_ckpt_dir = os.path.abspath(os.path.join(gen_config.save_dir, \"checkpoints\"))\n",
    "        ckpt = tf.train.get_checkpoint_state(gen_ckpt_dir)\n",
    "        if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "            #print(\"Reading Gen model parameters from %s\" % ckpt.model_checkpoint_path)\n",
    "            model.saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        else: \n",
    "            raise ValueError(\"Please run the training first\")\n",
    "        # Run evals on development set and print their perplexity.\n",
    "        for bucket_id in xrange(len(gen_config.buckets)):\n",
    "            encoder_inputs, decoder_inputs, target_weights, inputs_len, target_len = \\\n",
    "                    data_utils.get_batch(gen_config, dev_set, bucket_id)\n",
    "            _, eval_loss, sample_ids = model.step(sess, encoder_inputs, decoder_inputs, \n",
    "                                        target_weights, inputs_len, target_len, bucket_id, True)\n",
    "            eval_ppx = math.exp(eval_loss) if eval_loss < 300 else float('inf')\n",
    "            print(\"eval: bucket %d loss %.4f perplexity %.2e\" % (bucket_id, eval_loss, eval_ppx))\n",
    "            # process the output for better demonstration.\n",
    "            queries = data_utils.clean(encoder_inputs, data_utils.PAD_ID)\n",
    "            answers = data_utils.clean(decoder_inputs[1:], data_utils.EOS_ID)\n",
    "            gens = data_utils.clean(sample_ids, data_utils.EOS_ID)\n",
    "            references = [[gen] for gen in gens]\n",
    "            # compute four BLEU score\n",
    "            for i in range(4):\n",
    "                bleu_score, _, _, _, _, _ = bleu.compute_bleu(references, answers, max_order = i+1)\n",
    "                print(\"BLEU %d sorces: %.4f\"%(i+1, 100 * bleu_score))\n",
    "            for i in range(3):\n",
    "                print(\"Q:\", \" \".join([tf.compat.as_str(rev_vocab[j]) for j in queries[i]]))\n",
    "                print(\"A:\", \" \".join([tf.compat.as_str(rev_vocab[j]) for j in answers[i]]))\n",
    "                print(\"G:\", \" \".join([tf.compat.as_str(rev_vocab[j]) for j in gens[i]]))\n",
    "                bleu_score, _, _, _, _, _ = bleu.compute_bleu([[gens[i]]], [answers[i]], max_order = 1)\n",
    "                print(\"BLEU sorces: %.4f\"%(100 * bleu_score))\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result: I eval different bucket([(5, 10), (10, 15), (20, 25), (40, 50)]) in the test data.\n",
    "I also show some demonstration during evaluation: \n",
    "Q is the quary, A is the real answer in the test data, G is the generated answer by our bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading development and training gen_data\n",
      "b_set:  133\n",
      "b_set:  1427\n",
      "b_set:  3007\n",
      "b_set:  1826\n",
      "INFO:tensorflow:Restoring parameters from /home/chenminghao/git_work/Chatbot_test/log/gen_models/checkpoints/gen.model-4000\n",
      "eval: bucket 0 loss 62.4131 perplexity 1.28e+27\n",
      "BLEU 1 sorces: 11.0192\n",
      "BLEU 2 sorces: 3.7036\n",
      "BLEU 3 sorces: 1.4920\n",
      "BLEU 4 sorces: 0.0000\n",
      "Q: _UNK dollars\n",
      "A: here you are .\n",
      "G: i ' m afraid not .\n",
      "BLEU sorces: 15.1633\n",
      "\n",
      "Q: it was funny .\n",
      "A: tell me about it , will you ?\n",
      "G: i ' m glad you like it .\n",
      "BLEU sorces: 25.0000\n",
      "\n",
      "Q: that is 0-0-0 ?\n",
      "A: no , that ' s 0-0 .\n",
      "G: yes , it ' s a very good time .\n",
      "BLEU sorces: 37.2251\n",
      "\n",
      "eval: bucket 1 loss 84.1989 perplexity 3.69e+36\n",
      "BLEU 1 sorces: 19.0895\n",
      "BLEU 2 sorces: 7.7853\n",
      "BLEU 3 sorces: 4.0111\n",
      "BLEU 4 sorces: 2.0204\n",
      "Q: do you have a free moment ?\n",
      "A: sure . what do you need ?\n",
      "G: yes , i have a few days .\n",
      "BLEU sorces: 12.3840\n",
      "\n",
      "Q: it happened at my house .\n",
      "A: was anything stolen ?\n",
      "G: i ' m sorry , sir . i ' ll have to get you in\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "Q: who is he marring ?\n",
      "A: a girl he met on holiday in spain , i think .\n",
      "G: he ' s a very good guy .\n",
      "BLEU sorces: 25.0000\n",
      "\n",
      "eval: bucket 2 loss 131.1962 perplexity 9.50e+56\n",
      "BLEU 1 sorces: 19.4189\n",
      "BLEU 2 sorces: 7.0425\n",
      "BLEU 3 sorces: 3.3453\n",
      "BLEU 4 sorces: 1.4859\n",
      "Q: food is less expensive in a cafeteria , because you serve yourself .\n",
      "A: how to do it ?\n",
      "G: i know , but i ' ve got a lot of fun .\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "Q: which _UNK do you use for ?\n",
      "A: i ' ll use ginger , garlic _UNK , hot pepper and vinegar .\n",
      "G: i have a good time .\n",
      "BLEU sorces: 14.2857\n",
      "\n",
      "Q: i should be able to return by next monday .\n",
      "A: fine . well , thanks for calling and letting me know you will be absent . i hope you feel better soon .\n",
      "G: i ' m sorry , sir . i ' ll have to get you in the office .\n",
      "BLEU sorces: 21.7391\n",
      "\n",
      "eval: bucket 3 loss 212.5710 perplexity 2.08e+92\n",
      "BLEU 1 sorces: 14.9888\n",
      "BLEU 2 sorces: 5.6044\n",
      "BLEU 3 sorces: 2.6635\n",
      "BLEU 4 sorces: 1.3131\n",
      "Q: well , known , jim , i ' m . . . i ' m pretty much in favour of your computers , i think computers teach kids to think , because they require logical thoughts .\n",
      "A: but i . . . i don ' t agree with _UNK computers weaken kids ' ability to _UNK kids don ' t learn basic skills .\n",
      "G: i ' ve heard that , but i ' ve got a lot of fun .\n",
      "BLEU sorces: 22.2222\n",
      "\n",
      "Q: it sounds easy when you say it like that . in reality , it ' s harder to make peace between countries .\n",
      "A: yes , it is . one way to stop countries fighting is to cut off their financial support . wars are very expensive .\n",
      "G: i ' ve heard that it ' s a bit too long .\n",
      "BLEU sorces: 8.3333\n",
      "\n",
      "Q: i ' m a tv announcer . don ' t you recognize me ? i do the weather report on _UNK !\n",
      "A: gee , i ' m sorry . i don ' t watch tv .\n",
      "G: i ' m sorry , sir . we ' ll have to get there for you .\n",
      "BLEU sorces: 46.1210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    eval(gen_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "As we can see from the demonstration, the neural network has learn the language model very well and it is trying to answer the question: for example, Q: do you have a free moment ? G: yes , i have a few days . the bot has awared that it should answer yes or no and say something about it own time. We only use basic Seq2seq and train it only 4000 steps. It is a little incredible to see the nice result.\n",
    "\n",
    "However, we can see that BLEU score is no high and the bot always say some common things: i ' m sorry; i ' ve heard that. and the bot can't answer a little difficult question: Q: who is he marring ? G: he ' s a very good guy .\n",
    "\n",
    "Thus, the bot can't understand (recognize the pattern in language) complex sentence (for example, he can't spot the relation between the weather report and TV).\n",
    "\n",
    "We have to train more steps, tune the parameters, and use more advance model to deal with the problem. In next notebook, we hope we can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's try the movie data**\n",
    "\n",
    "You can download it at http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
    "\n",
    "Rename the train_data and dev_data as 'chat.in' and 'chat_test.in', and place them at 'movie_data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading development and training gen_data\n",
      "  reading data line 100000\n",
      "  reading data line 200000\n"
     ]
    }
   ],
   "source": [
    "gen_config.train_dir = 'movie_data'\n",
    "gen_config.save_dir = 'log/movie_gen_models'\n",
    "#prepare the movie_data\n",
    "vocab, rev_vocab, dev_set, train_set = data_utils.prepare_data(gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading development and training gen_data\n",
      "  reading data line 100000\n",
      "  reading data line 200000\n",
      "b_set:  17348\n",
      "b_set:  53076\n",
      "b_set:  74236\n",
      "b_set:  57741\n",
      "Creating 1 layers of 128 units.\n",
      "creat gen_model time: 1.459\n",
      "Begin training...\n",
      "Record every 500 steps\n",
      " step:  500  step_loss: 44.8226 step_time:  0.1116 bucket:2 \n",
      " global step 500 learning rate 0.5000 step-time 0.12 loss 63.3052 perplexity 3.11e+27\n",
      " step: 1000  step_loss: 45.1348 step_time:  0.1099 bucket:2 \n",
      " global step 1000 learning rate 0.5000 step-time 0.12 loss 51.3296 perplexity 1.96e+22\n",
      " step: 1500  step_loss: 26.7986 step_time:  0.0704 bucket:1 \n",
      " global step 1500 learning rate 0.5000 step-time 0.13 loss 49.1661 perplexity 2.25e+21\n",
      " step: 2000  step_loss: 42.6318 step_time:  0.1101 bucket:2 \n",
      " global step 2000 learning rate 0.5000 step-time 0.13 loss 48.2005 perplexity 8.57e+20\n",
      " step: 2500  step_loss: 44.6767 step_time:  0.1136 bucket:2 \n",
      " global step 2500 learning rate 0.5000 step-time 0.12 loss 45.8265 perplexity 7.98e+19\n",
      " step: 3000  step_loss: 45.0123 step_time:  0.1107 bucket:2 \n",
      " global step 3000 learning rate 0.5000 step-time 0.13 loss 46.0515 perplexity 1.00e+20\n",
      " step: 3500  step_loss: 40.5468 step_time:  0.1106 bucket:2 \n",
      " global step 3500 learning rate 0.5000 step-time 0.13 loss 45.0619 perplexity 3.72e+19\n",
      " step: 4000  step_loss: 25.3222 step_time:  0.0700 bucket:1 \n",
      " global step 4000 learning rate 0.5000 step-time 0.12 loss 41.3674 perplexity 9.24e+17\n",
      " step: 4500  step_loss: 42.4025 step_time:  0.1107 bucket:2 \n",
      " global step 4500 learning rate 0.5000 step-time 0.12 loss 43.1049 perplexity 5.25e+18\n",
      " step: 5000  step_loss: 73.8439 step_time:  0.2123 bucket:3 \n",
      " global step 5000 learning rate 0.5000 step-time 0.12 loss 41.7899 perplexity 1.41e+18\n",
      " step: 5500  step_loss: 23.7353 step_time:  0.0707 bucket:1 \n",
      " global step 5500 learning rate 0.5000 step-time 0.12 loss 42.8790 perplexity 4.19e+18\n",
      " step: 6000  step_loss: 23.0330 step_time:  0.0725 bucket:1 \n",
      " global step 6000 learning rate 0.5000 step-time 0.12 loss 42.7384 perplexity 3.64e+18\n",
      " step: 6500  step_loss: 41.0410 step_time:  0.1129 bucket:2 \n",
      " global step 6500 learning rate 0.5000 step-time 0.12 loss 42.1453 perplexity 2.01e+18\n",
      " step: 7000  step_loss: 40.9762 step_time:  0.1109 bucket:2 \n",
      " global step 7000 learning rate 0.5000 step-time 0.12 loss 41.3287 perplexity 8.89e+17\n",
      " step: 7500  step_loss: 73.0517 step_time:  0.2094 bucket:3 \n",
      " global step 7500 learning rate 0.5000 step-time 0.12 loss 42.4053 perplexity 2.61e+18\n",
      " step: 8000  step_loss: 72.1117 step_time:  0.2087 bucket:3 \n",
      " global step 8000 learning rate 0.5000 step-time 0.12 loss 40.7658 perplexity 5.06e+17\n",
      "current_step: 8000, save model to log/movie_gen_models/checkpoints\n"
     ]
    }
   ],
   "source": [
    "gen_config.pretrain_steps = 8000\n",
    "gen_config.steps_per_checkpoint = 500\n",
    "with tf.Graph().as_default():\n",
    "    log_data = train(gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEjCAYAAABeoiSAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f42487fde48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "log_t = log_data['t']\n",
    "log_loss = log_data['loss']\n",
    "log_plot= plt.figure()\n",
    "plt.plot(log_t, log_loss, label='teacher focusing loss')\n",
    "plt.suptitle('Basic Seq2seq Training Loss (movie_data)', fontsize=20)\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "plt.ylabel('MLE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading development and training gen_data\n",
      "  reading data line 100000\n",
      "  reading data line 200000\n",
      "b_set:  422\n",
      "b_set:  1065\n",
      "b_set:  1742\n",
      "b_set:  1409\n",
      "INFO:tensorflow:Restoring parameters from /home/chenminghao/git_work/Chatbot_test/log/movie_gen_models/checkpoints/gen.model-8000\n",
      "eval: bucket 0 loss 54.1671 perplexity 3.35e+23\n",
      "BLEU 1 sorces: 4.3951\n",
      "BLEU 2 sorces: 2.0357\n",
      "BLEU 3 sorces: 1.1812\n",
      "BLEU 4 sorces: 0.6903\n",
      "Q: in there .\n",
      "A: show me .\n",
      "G: i ' m sorry , i didn ' t want\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "Q: no .\n",
      "A: why not ?\n",
      "G: i ' m sorry , i didn ' t want\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "Q: maestro .\n",
      "A: good morning .\n",
      "G: i ' m sorry , i didn ' t want\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "eval: bucket 1 loss 75.4207 perplexity 5.69e+32\n",
      "BLEU 1 sorces: 8.3771\n",
      "BLEU 2 sorces: 3.6706\n",
      "BLEU 3 sorces: 1.9223\n",
      "BLEU 4 sorces: 1.1393\n",
      "Q: which one pulled the trigger ?\n",
      "A: the indian . i was about 30 yards away .\n",
      "G: i don ' t know .\n",
      "BLEU sorces: 20.0000\n",
      "\n",
      "Q: did you like it , then ?\n",
      "A: how could i not ?\n",
      "G: i didn ' t know what you said , but i didn ' t want\n",
      "BLEU sorces: 2.7067\n",
      "\n",
      "Q: mrs . christian , tom welles here .\n",
      "A: how are you ? having any luck ?\n",
      "G: i ' m sorry , i can ' t . i ' m sorry ,\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "eval: bucket 2 loss 119.7977 perplexity 1.07e+52\n",
      "BLEU 1 sorces: 15.6043\n",
      "BLEU 2 sorces: 7.4979\n",
      "BLEU 3 sorces: 4.3509\n",
      "BLEU 4 sorces: 2.5064\n",
      "Q: why haven ' t you called ? why don ' t you answer your phone ?\n",
      "A: i don ' t know . i ' m sorry . . .\n",
      "G: i don ' t know . i just wanted to go to the house . i was a _UNK ,\n",
      "BLEU sorces: 35.9166\n",
      "\n",
      "Q: do you think things will be a lot different on mercury , dad ?\n",
      "A: it ' s going to be terrific . a whole new world , new kids to play with .\n",
      "G: i don ' t think so .\n",
      "BLEU sorces: 10.5263\n",
      "\n",
      "Q: ted ! what are you . . . ?\n",
      "A: i have to get in there . i have to stop this flight .\n",
      "G: i ' m a _UNK , _UNK , and i am a _UNK , and i am a _UNK ,\n",
      "BLEU sorces: 9.3063\n",
      "\n",
      "eval: bucket 3 loss 193.0755 perplexity 7.11e+83\n",
      "BLEU 1 sorces: 18.3055\n",
      "BLEU 2 sorces: 9.2790\n",
      "BLEU 3 sorces: 5.2074\n",
      "BLEU 4 sorces: 2.5905\n",
      "Q: i ' ll wish you a happy birthday now and i ' ll see you soon . all right , darling ?\n",
      "A: yes , daddy .\n",
      "G: i ' m sorry , i ' m sorry , i ' m sorry , i ' m sorry ,\n",
      "BLEU sorces: 0.4579\n",
      "\n",
      "Q: expressing my opinion is not a terrorist action .\n",
      "A: well , yes , compared to your other choices of expression this year , today ' s events are quite mild . by the way , bobby _UNK ' s _UNK retrieval operation went quite well , in case you ' re interested .\n",
      "G: i ' m sorry , i can ' t .\n",
      "BLEU sorces: 9.0909\n",
      "\n",
      "Q: oh , yes ! do that ! you treat me right , man . tell me all about yourself , your roots , your personal life , your childhood dreams . . .\n",
      "A: i don ' t think this is a good time . . .\n",
      "G: i ' m sorry , i didn ' t want to be a real thing , i can ' t\n",
      "BLEU sorces: 17.9583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    eval(gen_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, movie data is more noise and may need preprocess and much more training. The bot is kind of afraid of make mistake and confused by the noisy data, so it always say: i ' m sorry. i don ' t know .\n",
    "\n",
    "These dull answer are also needed to be solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
