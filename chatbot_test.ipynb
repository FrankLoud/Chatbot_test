{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick but complete test of Seq2seq Chatbot\n",
    "\n",
    "This is the first part of my Chatbot test. I'll look into the performance of some famous deep learning methods for NLP tesk. Thus, I adopt the quickest implement of Seq2seq Chatbot by Tensorflow's new rnn API. Hope you and me will get some insight into Seq2seq after completing the notebook.\n",
    "\n",
    "Prerequisits(only recommend):\n",
    "\n",
    "- python 3.5 or 3.6\n",
    "\n",
    "- tensorflow 1.4.0 (cpu)\n",
    "\n",
    "- Tensorflow's new Seq2seq API tutorial: https://www.tensorflow.org/tutorials/seq2seq\n",
    "\n",
    "- (optinal)A Tensorflow's legacy_seq2seq Chatbot: https://github.com/nicolas-ivanov/tf_seq2seq_chatbot  \n",
    "(Tensorflow's legacy_seq2seq is not as flexiable as Tensorflow's new Seq2seq, but it's more fundamental.)\n",
    "\n",
    "- CS224n or other deep learning in NLP course.\n",
    "(Because this notebook has few theoretical instruction)\n",
    "\n",
    "If you are Chinese, you are recommended to read a better instruction at zhihu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ignore warnings for better demonstration\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Make tensorflow less verbose; filter out info (1+) and warnings (2+) but not errors (3).\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "from six.moves import xrange\n",
    "print(tf.__version__)\n",
    "\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set seed\n",
    "SEED = 0\n",
    "tf.set_random_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "#set config\n",
    "class gen_config(object):\n",
    "    initialize = True\n",
    "    learning_rate = 0.5\n",
    "    learning_rate_decay_factor = 0.99\n",
    "    batch_size = 128\n",
    "    emb_dim = 128 # 512\n",
    "    num_layers = 1 # 2\n",
    "    vocab_size = 20000\n",
    "    max_gradient_norm = 5.0\n",
    "    steps_per_checkpoint = 200\n",
    "    pretrain_steps = 4000\n",
    "    train_dir = 'data' # 'movie_data'\n",
    "    save_dir = 'log/gen_models' #'log/movie_gen_models'\n",
    "    tensorboard_dir = 'log/tensorboard'\n",
    "    buckets = [(5, 10), (10, 15), (20, 25), (40, 50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "I use the DailyDialog from http://yanran.li/dailydialog\n",
    "> Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset. IJCNLP 2017.\n",
    "\n",
    "I will also test the Cornell Movie-Dialogs Corpus http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
    "> \"Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs\"\n",
    "Cristian Danescu-Niculescu-Mizil and Lillian Lee\n",
    "Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics, ACL 2011.\n",
    "\n",
    "I have check the OpenSubtitles and Reddit comments(https://github.com/julien-c/chatbot-rnn), but those corpus are more large and noisy.\n",
    "\n",
    "data_utils.py deal with the training and test data. You can look into data_utils.py for detailed instruction of data processing.\n",
    "In short, data_utils.prepare_data will create vocabularies, tokenize data, and return vocab, rev_vocab, dev_set, train_set:\n",
    "\n",
    "dev_set or train_set: a list of length len(buckets); data_set[n] contains a list of\n",
    "      (source, target) pairs read from the provided data files that fit into the n-th bucket\n",
    "\n",
    "You can have a look at a few train data during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocabulary data/vocab20000.in from data data/chat.in\n",
      "  processing line 100000\n",
      "Tokenizing data in data/chat.in\n",
      "  tokenizing line 10000\n",
      "  quary:  What time ?\n",
      "   answer:  At 8 o'clock . I will make the reservation .\n",
      "\n",
      "  tokenizing line 20000\n",
      "  quary:  Ok . Can I ask who is calling , please ?\n",
      "   answer:  This is Nathaniel Brown .\n",
      "\n",
      "  tokenizing line 30000\n",
      "  quary:  I usually take the 5 thirty home .\n",
      "   answer:  And can you get a seat ?\n",
      "\n",
      "  tokenizing line 40000\n",
      "  quary:  Can you tell me something about the Spring Festival ?\n",
      "   answer:  Just like you celebrate Christmas , we celebrate our lunar New Year's Day , the Spring Festival . It is a time for the family members and relatives to have a get-together .\n",
      "\n",
      "  tokenizing line 50000\n",
      "  quary:  That's a cool jacket . Where did you get it ?\n",
      "   answer:  I bought it when I was on vacation in Nepal .\n",
      "\n",
      "  tokenizing line 60000\n",
      "  quary:  You've got to be joking .\n",
      "   answer:  No , I'm not .\n",
      "\n",
      "  tokenizing line 70000\n",
      "  quary:  Don ’ t tell me ! I ’ m sure it ’ s someplace warm and sunny with great beaches !\n",
      "   answer:  You got it ! I ’ m going to spend two fabulous weeks in Hawaii !\n",
      "\n",
      "  tokenizing line 80000\n",
      "  quary:  It can't be that bad .\n",
      "   answer:  I wish it wasn't , but there is actually a lot of crime and prostitution around here .\n",
      "\n",
      "  tokenizing line 90000\n",
      "  quary:  I'm very busy these days . It seems I can never finish my work .\n",
      "   answer:  Well , take it easy ! Don't let it get on top of you .\n",
      "\n",
      "  tokenizing line 100000\n",
      "  quary:  You don't sound too excited about going to your reunion .\n",
      "   answer:  I'm not . I get a stomachache just thinking about it .\n",
      "\n",
      "  tokenizing line 110000\n",
      "  quary:  This is Ryan . How may I help you ?\n",
      "   answer:  Ryan , this is Malia , and I am afraid that I am feeling a bit under the weather .\n",
      "\n",
      "  tokenizing line 120000\n",
      "  quary:  Do you have a lot on your mind when you try to go to sleep ?\n",
      "   answer:  My mother is ill with cancer , and I think about her a lot .\n",
      "\n",
      "  tokenizing line 130000\n",
      "  quary:  I'd like to see it for myself .\n",
      "   answer:  Go right ahead .\n",
      "\n",
      "  tokenizing line 140000\n",
      "  quary:  Yes , of course . When you hear the fire alarm , which is a very loud , continuous ringing noise , you should go to the nearest fire exit or fire escape as quickly as possible .\n",
      "   answer:  Should we use the stairs ?\n",
      "\n",
      "  tokenizing line 150000\n",
      "  quary:  No . I'd like to do something special for you on your birthday .\n",
      "   answer:  I'd like that . Alright , put on this apron first .\n",
      "\n",
      "Tokenizing data in data/chat_test.in\n",
      "  tokenizing line 10000\n",
      "  quary:  Really ?\n",
      "   answer:  But I think Henry is a backroom boy.He always helps her with her study .\n",
      "\n",
      "Reading development and training gen_data\n"
     ]
    }
   ],
   "source": [
    "#prepare the data\n",
    "vocab, rev_vocab, dev_set, train_set = data_utils.prepare_data(gen_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "I only build basic seq2seq in this notebook(only one layer, without attention). In the next notebook, I will test more advance model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build Craph\n",
    "class Seq2SeqModel(object):\n",
    "    def __init__(self, config, name_scope, forward_only=False, num_samples=512, dtype=tf.float32):\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.emb_dim = config.emb_dim\n",
    "        self.buckets = config.buckets\n",
    "        self.learning_rate = tf.Variable(float(config.learning_rate), name=\"learning_rate\", \n",
    "                                         trainable=False, dtype=dtype)\n",
    "        self.learning_rate_decay_op = self.learning_rate.assign(\n",
    "                                        self.learning_rate * config.learning_rate_decay_factor)\n",
    "        self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        self.batch_size = config.batch_size\n",
    "        self.num_layers = config.num_layers\n",
    "        self.max_gradient_norm = config.max_gradient_norm\n",
    "        self.forward_only = tf.placeholder(tf.bool, name=\"forward_only\")\n",
    "        # Feeds for inputs. shape: [seq_len, batch]\n",
    "        self.encoder_inputs = tf.placeholder(tf.int32, shape=[None, None], name=\"encoder_inputs\")\n",
    "        self.decoder_inputs = tf.placeholder(tf.int32, shape=[None, None], name=\"decoder_inputs\")\n",
    "        self.targets = tf.placeholder(tf.int32, shape=[None, None], name=\"targets\")\n",
    "        self.target_weights = tf.placeholder(tf.float32, shape=[None, None], name=\"target_weight\")\n",
    "        self.inputs_len = tf.placeholder(tf.int32, shape=[None])\n",
    "        self.target_len = tf.placeholder(tf.int32, shape=[None])\n",
    "        size = self.emb_dim\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_embedding = tf.get_variable(\n",
    "                \"encoder_embedding\", [self.vocab_size, self.emb_dim], dtype=tf.float32)\n",
    "        embed_inputs = tf.nn.embedding_lookup(self.enc_embedding, self.encoder_inputs)\n",
    "            # shape: [seq_len, batch, emb_dim]\n",
    "        # Encoder\n",
    "        encoder_cell = tf.nn.rnn_cell.GRUCell(size)\n",
    "        if self.num_layers > 1:\n",
    "            encoder_cell = tf.nn.rnn_cell.MultiRNNCell([encoder_cell] * self.num_layers)\n",
    "        # Dynamic encoding\n",
    "        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "            encoder_cell, embed_inputs, dtype=tf.float32, \n",
    "            sequence_length=self.inputs_len, time_major=True)\n",
    "        \n",
    "        # Output projection layer\n",
    "        with tf.variable_scope(\"output_projection\"):\n",
    "            self.output_layer = tf.layers.Dense(self.vocab_size)\n",
    "            self.output_layer.build(size)\n",
    "            # w and b are used in sample_loss\n",
    "            w = self.output_layer.kernel\n",
    "            w_t = tf.transpose(w)\n",
    "            b = self.output_layer.bias\n",
    "\n",
    "        # Decoder\n",
    "        embed_targets = tf.nn.embedding_lookup(self.enc_embedding, self.decoder_inputs)\n",
    "        decoder_cell = tf.nn.rnn_cell.GRUCell(size)\n",
    "        if self.num_layers > 1:\n",
    "            decoder_cell = tf.nn.rnn_cell.MultiRNNCell([decoder_cell] * self.num_layers)\n",
    "        if not forward_only:\n",
    "            # teacher focusing\n",
    "            helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                embed_targets, self.target_len, time_major=True)\n",
    "        else:\n",
    "            start_tokens = tf.fill([self.batch_size], data_utils.GO_ID)\n",
    "            end_token = -1 \n",
    "            # we dont need EOS to finish decoding(for compating with the shape of self.targets)\n",
    "            helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                self.enc_embedding, start_tokens, end_token)\n",
    "        # creat decoder\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper, encoder_state, \n",
    "            output_layer=None if not forward_only else self.output_layer)\n",
    "\n",
    "        # Dynamic decoding\n",
    "        outputs, final_context_state, final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder,\n",
    "            maximum_iterations=None if not forward_only else tf.reduce_max(self.target_len),\n",
    "            output_time_major=True,\n",
    "            swap_memory=True)\n",
    "        self.sample_id = outputs.sample_id\n",
    "        self.logits = outputs.rnn_output\n",
    "        \n",
    "        # Loss\n",
    "        # we use sampled_loss to speed up.\n",
    "        def sampled_loss(labels, logits):\n",
    "            labels = tf.reshape(labels, [-1, 1])\n",
    "            return tf.cast(\n",
    "                tf.nn.sampled_softmax_loss(weights=w_t, biases=b, inputs=logits, labels=labels,\n",
    "                                    num_sampled=num_samples, num_classes=self.vocab_size), dtype)\n",
    "        if not forward_only:\n",
    "            self.loss = tf.contrib.seq2seq.sequence_loss(logits=self.logits, targets=self.targets, \n",
    "                                                         weights=self.target_weights,\n",
    "                                                        average_across_timesteps=False,\n",
    "                                                        average_across_batch=False,\n",
    "                                                        softmax_loss_function=sampled_loss)\n",
    "            self.loss = tf.reduce_sum(self.loss) / tf.to_float(self.batch_size)\n",
    "            \n",
    "        else:\n",
    "            crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels=self.targets, logits=self.logits)\n",
    "            self.loss = tf.reduce_sum(crossent * self.target_weights)/tf.to_float(self.batch_size)\n",
    "            \n",
    "        # Gradient Descent\n",
    "        params = tf.trainable_variables()\n",
    "        if not forward_only:\n",
    "            opt = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "            gradients = tf.gradients(self.loss, params)\n",
    "            clipped_gradients, norm = tf.clip_by_global_norm(gradients, self.max_gradient_norm)\n",
    "            self.gradient_norm=norm\n",
    "            self.update=opt.apply_gradients(zip(clipped_gradients, params), \n",
    "                                            global_step=self.global_step)\n",
    "\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "    # train the model or test the model for one batch.\n",
    "    def step(self, session, encoder_inputs, decoder_inputs, target_weights, \n",
    "             inputs_len, target_len, bucket_id, forward_only):\n",
    "        \n",
    "        encoder_size, decoder_size = self.buckets[bucket_id]\n",
    "        # Input feed: encoder inputs, decoder inputs, target_weights, as provided.\n",
    "        input_feed = {}\n",
    "        input_feed[self.encoder_inputs] = encoder_inputs\n",
    "        input_feed[self.decoder_inputs] = decoder_inputs\n",
    "        input_feed[self.target_weights] = target_weights\n",
    "        # Our targets are decoder inputs shifted by one.\n",
    "        input_feed[self.targets] = decoder_inputs[1:]+[np.zeros([self.batch_size],dtype=np.int32)]\n",
    "\n",
    "        input_feed[self.inputs_len] = inputs_len\n",
    "        input_feed[self.target_len] = np.ones([self.batch_size], dtype=np.int32)* decoder_size\n",
    "        # Output feed: depends on whether we do a backward step or not.\n",
    "        if not forward_only:\n",
    "            output_feed = [self.update,  # Update Op that does SGD.\n",
    "                         self.gradient_norm,  # Gradient norm.\n",
    "                         self.loss]  # Loss for this batch.\n",
    "        else:\n",
    "            output_feed = [self.loss]  # Loss for this batch.\n",
    "            for l in xrange(decoder_size if decoder_size<20 else 20):  # Output logits.\n",
    "                output_feed.append(self.sample_id[l])\n",
    "\n",
    "        outputs = session.run(output_feed, input_feed)\n",
    "        if not forward_only:\n",
    "            return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.\n",
    "        else:\n",
    "            return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(gen_config):\n",
    "    # creating and loading the vocabulary and the train and dev data\n",
    "    vocab, rev_vocab, dev_set, train_set = data_utils.prepare_data(gen_config)\n",
    "    for b_set in train_set:\n",
    "        print(\"b_set: \", len(b_set))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print(\"Creating %d layers of %d units.\" % (gen_config.num_layers, gen_config.emb_dim))\n",
    "        creat_time = time.time()\n",
    "        model = Seq2SeqModel(gen_config, name_scope=\"Basic_Seq2seq\", forward_only=False,\n",
    "                                        dtype=tf.float32)\n",
    "        sess.run(tf.variables_initializer(tf.global_variables()))\n",
    "        print(\"creat gen_model time: %.3f\" % (time.time()-creat_time))\n",
    "\n",
    "        # This is the training loop.\n",
    "        step_time, loss = 0.0, 0.0\n",
    "        current_step = 0\n",
    "        previous_losses = []\n",
    "        log_data = {'t':[], 'loss':[]}\n",
    "        \n",
    "        bucket_sizes=[len(train_set[b]) for b in range(len(gen_config.buckets))]\n",
    "        \n",
    "        print(\"Begin training...\")\n",
    "        print(\"Record every %d steps\" % gen_config.steps_per_checkpoint)\n",
    "        while current_step < gen_config.pretrain_steps:\n",
    "            # Choose a bucket according to data distribution.\n",
    "            bucket_id = data_utils.get_bucket_id(gen_config, bucket_sizes)\n",
    "\n",
    "            # Get a batch and make a step.\n",
    "            start_time = time.time()\n",
    "            encoder_inputs, decoder_inputs, target_weights, inputs_len, target_len = \\\n",
    "                    data_utils.get_batch(gen_config, train_set, bucket_id)\n",
    "\n",
    "            _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, \n",
    "                                         inputs_len, target_len, bucket_id, forward_only=False)\n",
    "\n",
    "            step_time += (time.time() - start_time) / gen_config.steps_per_checkpoint\n",
    "            loss += step_loss / gen_config.steps_per_checkpoint\n",
    "            current_step += 1\n",
    "            print(\"\\r step:{:5}  step_loss:{:8.4f} step_time:{:8.4f} bucket:{}\".format(\n",
    "                current_step, step_loss, time.time() - start_time, bucket_id), end=' ')\n",
    "            # Once in a while, we print statistics.\n",
    "            if current_step % gen_config.steps_per_checkpoint == 0:\n",
    "                # Print statistics for the previous epoch.\n",
    "                perplexity = math.exp(loss) if loss < 300 else float('inf')\n",
    "                print(\"\\n global step %d learning rate %.4f step-time %.2f loss %.4f perplexity \"\n",
    "                      \"%.2e\" % (model.global_step.eval(), model.learning_rate.eval(),\n",
    "                                step_time, loss, perplexity))\n",
    "                # Decrease learning rate if no improvement was seen over last 3 times.\n",
    "                if len(previous_losses) > 2 and loss > max(previous_losses[-3:]):\n",
    "                    sess.run(model.learning_rate_decay_op)\n",
    "                previous_losses.append(loss)\n",
    "                log_data['t'].append(current_step)\n",
    "                log_data['loss'].append(loss)\n",
    "                step_time, loss = 0.0, 0.0\n",
    "                sys.stdout.flush()\n",
    "        # Save model\n",
    "        gen_ckpt_dir = os.path.abspath(os.path.join(gen_config.save_dir, \"checkpoints\"))\n",
    "        if gfile.Exists(gen_ckpt_dir):\n",
    "            gfile.DeleteRecursively(gen_ckpt_dir)\n",
    "        gfile.MakeDirs(gen_ckpt_dir)\n",
    "        checkpoint_path = os.path.join(gen_ckpt_dir, \"gen.model\")\n",
    "        print(\"current_step: %d, save model to %s\" % (current_step, \n",
    "                            os.path.join(gen_config.save_dir, \"checkpoints\")))\n",
    "        model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n",
    "        return log_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Let's begin training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading development and training gen_data\n",
      "b_set:  1785\n",
      "b_set:  16959\n",
      "b_set:  33353\n",
      "b_set:  20381\n",
      "Creating 1 layers of 128 units.\n",
      "creat gen_model time: 1.207\n",
      "Begin training...\n",
      "Record every 200 steps\n",
      " step:  200  step_loss: 59.0128 step_time:  0.2088 bucket:2 \n",
      " global step 200 learning rate 0.5000 step-time 0.19 loss 81.8201 perplexity 3.42e+35\n",
      " step:  400  step_loss: 31.2742 step_time:  0.0935 bucket:1  \n",
      " global step 400 learning rate 0.5000 step-time 0.20 loss 62.8486 perplexity 1.97e+27\n",
      " step:  600  step_loss: 86.7572 step_time:  0.2348 bucket:3   \n",
      " global step 600 learning rate 0.5000 step-time 0.19 loss 55.9051 perplexity 1.90e+24\n",
      " step:  800  step_loss: 43.6771 step_time:  0.1829 bucket:2 \n",
      " global step 800 learning rate 0.5000 step-time 0.19 loss 52.1704 perplexity 4.54e+22\n",
      " step: 1000  step_loss: 45.3504 step_time:  0.2258 bucket:2 \n",
      " global step 1000 learning rate 0.5000 step-time 0.20 loss 53.7342 perplexity 2.17e+23\n",
      " step: 1200  step_loss: 42.0338 step_time:  0.1213 bucket:2  \n",
      " global step 1200 learning rate 0.5000 step-time 0.19 loss 49.7335 perplexity 3.97e+21\n",
      " step: 1400  step_loss: 82.3244 step_time:  0.3644 bucket:3  \n",
      " global step 1400 learning rate 0.5000 step-time 0.21 loss 52.0533 perplexity 4.04e+22\n",
      " step: 1600  step_loss: 27.1018 step_time:  0.1008 bucket:1 \n",
      " global step 1600 learning rate 0.5000 step-time 0.20 loss 49.4393 perplexity 2.96e+21\n",
      " step: 1800  step_loss: 40.4441 step_time:  0.2228 bucket:2 \n",
      " global step 1800 learning rate 0.5000 step-time 0.18 loss 47.8799 perplexity 6.22e+20\n",
      " step: 2000  step_loss: 42.0238 step_time:  0.1753 bucket:2  \n",
      " global step 2000 learning rate 0.5000 step-time 0.19 loss 46.1180 perplexity 1.07e+20\n",
      " step: 2200  step_loss: 21.1600 step_time:  0.1219 bucket:1  \n",
      " global step 2200 learning rate 0.5000 step-time 0.20 loss 45.0652 perplexity 3.73e+19\n",
      " step: 2400  step_loss: 38.4520 step_time:  0.1560 bucket:2   \n",
      " global step 2400 learning rate 0.5000 step-time 0.20 loss 45.2263 perplexity 4.38e+19\n",
      " step: 2600  step_loss: 38.8093 step_time:  0.1468 bucket:2 \n",
      " global step 2600 learning rate 0.5000 step-time 0.20 loss 45.1872 perplexity 4.21e+19\n",
      " step: 2800  step_loss: 36.5381 step_time:  0.1703 bucket:2  \n",
      " global step 2800 learning rate 0.5000 step-time 0.20 loss 43.5901 perplexity 8.53e+18\n",
      " step: 3000  step_loss: 36.6104 step_time:  0.1606 bucket:2 \n",
      " global step 3000 learning rate 0.5000 step-time 0.20 loss 44.2326 perplexity 1.62e+19\n",
      " step: 3200  step_loss: 35.4241 step_time:  0.2247 bucket:2  \n",
      " global step 3200 learning rate 0.5000 step-time 0.20 loss 42.7334 perplexity 3.62e+18\n",
      " step: 3400  step_loss: 71.0401 step_time:  0.3446 bucket:3    \n",
      " global step 3400 learning rate 0.5000 step-time 0.20 loss 43.8326 perplexity 1.09e+19\n",
      " step: 3600  step_loss: 37.9776 step_time:  0.2116 bucket:2 \n",
      " global step 3600 learning rate 0.5000 step-time 0.19 loss 41.0288 perplexity 6.59e+17\n",
      " step: 3800  step_loss: 22.7297 step_time:  0.0778 bucket:1     \n",
      " global step 3800 learning rate 0.5000 step-time 0.19 loss 40.5447 perplexity 4.06e+17\n",
      " step: 4000  step_loss: 38.6342 step_time:  0.1800 bucket:2    \n",
      " global step 4000 learning rate 0.5000 step-time 0.18 loss 37.8873 perplexity 2.85e+16\n",
      "current_step: 4000, save model to log/gen_models/checkpoints\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    log_data = train(gen_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training result seems not bad. Let's plot the training process for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEjCAYAAAA/ugbCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY0KcJQJjjAlx/w/t8vANsO7oVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff69048af28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "log_t = log_data['t']\n",
    "log_loss = log_data['loss']\n",
    "log_plot= plt.figure()\n",
    "plt.plot(log_t, log_loss, label='teacher focusing loss')\n",
    "plt.suptitle('Basic Seq2seq Training Loss', fontsize=20)\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "plt.ylabel('MLE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "we use MLE loss and BLEU score(http://aclweb.org/anthology/P/P02/P02-1040.pdf) to evaluate.\n",
    "\n",
    "At training time, the decode mode is teacher focusing, while at test time, the decode mode is free running. Thus, the MLE loss is supposed to be much higher than it at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bleu\n",
    "def eval(gen_config):\n",
    "    vocab, rev_vocab, dev_set, train_set = data_utils.prepare_data(gen_config)\n",
    "    for b_set in dev_set:\n",
    "        print(\"b_set: \", len(b_set))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        model = Seq2SeqModel(gen_config, name_scope=\"Basic_Seq2seq\", forward_only=True,\n",
    "                                            dtype=tf.float32)\n",
    "        gen_ckpt_dir = os.path.abspath(os.path.join(gen_config.save_dir, \"checkpoints\"))\n",
    "        ckpt = tf.train.get_checkpoint_state(gen_ckpt_dir)\n",
    "        if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "            #print(\"Reading Gen model parameters from %s\" % ckpt.model_checkpoint_path)\n",
    "            model.saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        else: \n",
    "            raise ValueError(\"Please run the training first\")\n",
    "        # Run evals on development set and print their perplexity.\n",
    "        for bucket_id in xrange(len(gen_config.buckets)):\n",
    "            encoder_inputs, decoder_inputs, target_weights, inputs_len, target_len = \\\n",
    "                    data_utils.get_batch(gen_config, dev_set, bucket_id)\n",
    "            _, eval_loss, sample_ids = model.step(sess, encoder_inputs, decoder_inputs, \n",
    "                                        target_weights, inputs_len, target_len, bucket_id, True)\n",
    "            eval_ppx = math.exp(eval_loss) if eval_loss < 300 else float('inf')\n",
    "            print(\"eval: bucket %d loss %.4f perplexity %.2e\" % (bucket_id, eval_loss, eval_ppx))\n",
    "            # process the output for better demonstration.\n",
    "            queries = data_utils.clean(encoder_inputs, data_utils.PAD_ID)\n",
    "            answers = data_utils.clean(decoder_inputs[1:], data_utils.EOS_ID)\n",
    "            gens = data_utils.clean(sample_ids, data_utils.EOS_ID)\n",
    "            references = [[gen] for gen in gens]\n",
    "            for i in range(4):\n",
    "                bleu_score, _, _, _, _, _ = bleu.compute_bleu(references, answers, max_order = i+1)\n",
    "                print(\"BLEU %d sorces: %.4f\"%(i+1, 100 * bleu_score))\n",
    "            for i in range(3):\n",
    "                print(\"Q:\", \" \".join([tf.compat.as_str(rev_vocab[j]) for j in queries[i]]))\n",
    "                print(\"A:\", \" \".join([tf.compat.as_str(rev_vocab[j]) for j in answers[i]]))\n",
    "                print(\"G:\", \" \".join([tf.compat.as_str(rev_vocab[j]) for j in gens[i]]))\n",
    "                bleu_score, _, _, _, _, _ = bleu.compute_bleu([[gens[i]]], [answers[i]], max_order = 1)\n",
    "                print(\"BLEU sorces: %.4f\"%(100 * bleu_score))\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result: I eval different bucket([(5, 10), (10, 15), (20, 25), (40, 50)]) in the test data.\n",
    "I also show some demonstration during evaluation: \n",
    "Q is the quary, A is the real answer in the test data, G is the generated answer by our bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading development and training gen_data\n",
      "b_set:  133\n",
      "b_set:  1427\n",
      "b_set:  3007\n",
      "b_set:  1826\n",
      "INFO:tensorflow:Restoring parameters from /home/chenminghao/git_work/Chatbot_test/log/gen_models/checkpoints/gen.model-4000\n",
      "eval: bucket 0 loss 62.4131 perplexity 1.28e+27\n",
      "BLEU 1 sorces: 11.0192\n",
      "BLEU 2 sorces: 3.7036\n",
      "BLEU 3 sorces: 1.4920\n",
      "BLEU 4 sorces: 0.0000\n",
      "Q: _UNK dollars\n",
      "A: here you are .\n",
      "G: i ' m afraid not .\n",
      "BLEU sorces: 15.1633\n",
      "\n",
      "Q: it was funny .\n",
      "A: tell me about it , will you ?\n",
      "G: i ' m glad you like it .\n",
      "BLEU sorces: 25.0000\n",
      "\n",
      "Q: that is 0-0-0 ?\n",
      "A: no , that ' s 0-0 .\n",
      "G: yes , it ' s a very good time .\n",
      "BLEU sorces: 37.2251\n",
      "\n",
      "eval: bucket 1 loss 84.1989 perplexity 3.69e+36\n",
      "BLEU 1 sorces: 19.0895\n",
      "BLEU 2 sorces: 7.7853\n",
      "BLEU 3 sorces: 4.0111\n",
      "BLEU 4 sorces: 2.0204\n",
      "Q: do you have a free moment ?\n",
      "A: sure . what do you need ?\n",
      "G: yes , i have a few days .\n",
      "BLEU sorces: 12.3840\n",
      "\n",
      "Q: it happened at my house .\n",
      "A: was anything stolen ?\n",
      "G: i ' m sorry , sir . i ' ll have to get you in\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "Q: who is he marring ?\n",
      "A: a girl he met on holiday in spain , i think .\n",
      "G: he ' s a very good guy .\n",
      "BLEU sorces: 25.0000\n",
      "\n",
      "eval: bucket 2 loss 131.1962 perplexity 9.50e+56\n",
      "BLEU 1 sorces: 19.4189\n",
      "BLEU 2 sorces: 7.0425\n",
      "BLEU 3 sorces: 3.3453\n",
      "BLEU 4 sorces: 1.4859\n",
      "Q: food is less expensive in a cafeteria , because you serve yourself .\n",
      "A: how to do it ?\n",
      "G: i know , but i ' ve got a lot of fun .\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "Q: which _UNK do you use for ?\n",
      "A: i ' ll use ginger , garlic _UNK , hot pepper and vinegar .\n",
      "G: i have a good time .\n",
      "BLEU sorces: 14.2857\n",
      "\n",
      "Q: i should be able to return by next monday .\n",
      "A: fine . well , thanks for calling and letting me know you will be absent . i hope you feel better soon .\n",
      "G: i ' m sorry , sir . i ' ll have to get you in the office .\n",
      "BLEU sorces: 21.7391\n",
      "\n",
      "eval: bucket 3 loss 212.5710 perplexity 2.08e+92\n",
      "BLEU 1 sorces: 14.9888\n",
      "BLEU 2 sorces: 5.6044\n",
      "BLEU 3 sorces: 2.6635\n",
      "BLEU 4 sorces: 1.3131\n",
      "Q: well , known , jim , i ' m . . . i ' m pretty much in favour of your computers , i think computers teach kids to think , because they require logical thoughts .\n",
      "A: but i . . . i don ' t agree with _UNK computers weaken kids ' ability to _UNK kids don ' t learn basic skills .\n",
      "G: i ' ve heard that , but i ' ve got a lot of fun .\n",
      "BLEU sorces: 22.2222\n",
      "\n",
      "Q: it sounds easy when you say it like that . in reality , it ' s harder to make peace between countries .\n",
      "A: yes , it is . one way to stop countries fighting is to cut off their financial support . wars are very expensive .\n",
      "G: i ' ve heard that it ' s a bit too long .\n",
      "BLEU sorces: 8.3333\n",
      "\n",
      "Q: i ' m a tv announcer . don ' t you recognize me ? i do the weather report on _UNK !\n",
      "A: gee , i ' m sorry . i don ' t watch tv .\n",
      "G: i ' m sorry , sir . we ' ll have to get there for you .\n",
      "BLEU sorces: 46.1210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    eval(gen_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "As we can see from the demonstration, the neural network has learn the language model very well and it is trying to answer the question: for example, Q: do you have a free moment ? G: yes , i have a few days . the bot has awared that it should answer yes or no and say something about it own time. We only use basic Seq2seq and train it only 4000 steps. It is a little incredible to see the nice result.\n",
    "\n",
    "However, we can see that BLEU score is no high and the bot always say some common things: i ' m sorry; i ' ve heard that. and the bot can't answer a little difficult question: Q: who is he marring ? G: he ' s a very good guy .\n",
    "\n",
    "Thus, the bot can't understand (recognize the pattern in language) complex sentence (for example, he can't spot the relation between the weather report and TV).\n",
    "\n",
    "We have to use more advance model to deal with the problem and train more steps. In next notebook, we hope we can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's try the movie data**\n",
    "\n",
    "You can download it at http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
    "\n",
    "Rename the train_data and dev_data as 'chat.in' and 'chat_test.in', and place them at 'movie_data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading development and training gen_data\n",
      "  reading data line 100000\n",
      "  reading data line 200000\n"
     ]
    }
   ],
   "source": [
    "gen_config.train_dir = 'movie_data'\n",
    "gen_config.save_dir = 'log/movie_gen_models'\n",
    "#prepare the movie_data\n",
    "vocab, rev_vocab, dev_set, train_set = data_utils.prepare_data(gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading development and training gen_data\n",
      "  reading data line 100000\n",
      "  reading data line 200000\n",
      "b_set:  16874\n",
      "b_set:  52856\n",
      "b_set:  74550\n",
      "b_set:  58045\n",
      "Creating 1 layers of 128 units.\n",
      "creat gen_model time: 0.823\n",
      "Begin training...\n",
      "Record every 200 steps\n",
      " step:  200  step_loss: 38.9435 step_time:  0.1115 bucket:1 \n",
      " global step 200 learning rate 0.5000 step-time 0.18 loss 74.8483 perplexity 3.21e+32\n",
      " step:  400  step_loss: 51.7021 step_time:  0.1198 bucket:2 \n",
      " global step 400 learning rate 0.5000 step-time 0.19 loss 60.1260 perplexity 1.30e+26\n",
      " step:  600  step_loss: 48.9722 step_time:  0.1747 bucket:2  \n",
      " global step 600 learning rate 0.5000 step-time 0.18 loss 52.7606 perplexity 8.20e+22\n",
      " step:  800  step_loss: 44.4808 step_time:  0.1793 bucket:2   \n",
      " global step 800 learning rate 0.5000 step-time 0.17 loss 47.8700 perplexity 6.16e+20\n",
      " step: 1000  step_loss: 80.9724 step_time:  0.2769 bucket:3 \n",
      " global step 1000 learning rate 0.5000 step-time 0.19 loss 50.3812 perplexity 7.59e+21\n",
      " step: 1200  step_loss: 19.6827 step_time:  0.0523 bucket:0  \n",
      " global step 1200 learning rate 0.5000 step-time 0.18 loss 46.4307 perplexity 1.46e+20\n",
      " step: 1400  step_loss: 41.0908 step_time:  0.1627 bucket:2 \n",
      " global step 1400 learning rate 0.5000 step-time 0.19 loss 49.8905 perplexity 4.65e+21\n",
      " step: 1600  step_loss: 27.0541 step_time:  0.0750 bucket:1 \n",
      " global step 1600 learning rate 0.5000 step-time 0.20 loss 50.2167 perplexity 6.44e+21\n",
      " step: 1800  step_loss: 25.3545 step_time:  0.1278 bucket:1 \n",
      " global step 1800 learning rate 0.5000 step-time 0.19 loss 48.8504 perplexity 1.64e+21\n",
      " step: 2000  step_loss: 27.6136 step_time:  0.0791 bucket:1  \n",
      " global step 2000 learning rate 0.5000 step-time 0.18 loss 44.9481 perplexity 3.32e+19\n",
      " step: 2200  step_loss: 43.6132 step_time:  0.1516 bucket:2  \n",
      " global step 2200 learning rate 0.5000 step-time 0.18 loss 45.5296 perplexity 5.93e+19\n",
      " step: 2400  step_loss: 24.3709 step_time:  0.1038 bucket:1   \n",
      " global step 2400 learning rate 0.5000 step-time 0.19 loss 46.5469 perplexity 1.64e+20\n",
      " step: 2600  step_loss: 24.3640 step_time:  0.1475 bucket:1  \n",
      " global step 2600 learning rate 0.5000 step-time 0.18 loss 43.9417 perplexity 1.21e+19\n",
      " step: 2800  step_loss: 73.0805 step_time:  0.3458 bucket:3 \n",
      " global step 2800 learning rate 0.5000 step-time 0.18 loss 44.6170 perplexity 2.38e+19\n",
      " step: 3000  step_loss: 44.3316 step_time:  0.1223 bucket:2   \n",
      " global step 3000 learning rate 0.5000 step-time 0.19 loss 45.2024 perplexity 4.28e+19\n",
      " step: 3200  step_loss: 79.6739 step_time:  0.3884 bucket:3  \n",
      " global step 3200 learning rate 0.5000 step-time 0.18 loss 43.5228 perplexity 7.97e+18\n",
      " step: 3400  step_loss: 39.8858 step_time:  0.1773 bucket:2  \n",
      " global step 3400 learning rate 0.5000 step-time 0.20 loss 47.2303 perplexity 3.25e+20\n",
      " step: 3600  step_loss: 24.6820 step_time:  0.1127 bucket:1 \n",
      " global step 3600 learning rate 0.4950 step-time 0.19 loss 43.8914 perplexity 1.15e+19\n",
      " step: 3800  step_loss: 42.2487 step_time:  0.1631 bucket:2 \n",
      " global step 3800 learning rate 0.4950 step-time 0.18 loss 43.7352 perplexity 9.86e+18\n",
      " step: 4000  step_loss: 78.0680 step_time:  0.3743 bucket:3  \n",
      " global step 4000 learning rate 0.4950 step-time 0.18 loss 42.7311 perplexity 3.61e+18\n",
      "current_step: 4000, save model to log/movie_gen_models/checkpoints\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    log_data = train(gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEjCAYAAABeoiSAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15ec78fc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "log_t = log_data['t']\n",
    "log_loss = log_data['loss']\n",
    "log_plot= plt.figure()\n",
    "plt.plot(log_t, log_loss, label='teacher focusing loss')\n",
    "plt.suptitle('Basic Seq2seq Training Loss (movie_data)', fontsize=20)\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "plt.ylabel('MLE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading development and training gen_data\n",
      "  reading data line 100000\n",
      "  reading data line 200000\n",
      "b_set:  411\n",
      "b_set:  1067\n",
      "b_set:  1742\n",
      "b_set:  1415\n",
      "INFO:tensorflow:Restoring parameters from /home/chenminghao/git_work/Chatbot_test/log/movie_gen_models/checkpoints/gen.model-4000\n",
      "eval: bucket 0 loss 57.8539 perplexity 1.34e+25\n",
      "BLEU 1 sorces: 4.0609\n",
      "BLEU 2 sorces: 1.6006\n",
      "BLEU 3 sorces: 0.7852\n",
      "BLEU 4 sorces: 0.0000\n",
      "Q: well ?\n",
      "A: i ' m with <u>you ! </u>\n",
      "G: i ' m not sure you ' re not the\n",
      "BLEU sorces: 27.9188\n",
      "\n",
      "Q: who are you ?\n",
      "A: i brought the girl remember ?\n",
      "G: i ' m not sure you ' re not the\n",
      "BLEU sorces: 17.1139\n",
      "\n",
      "Q: what ?\n",
      "A: don ' t bother .\n",
      "G: i ' m not sure you ' re not the\n",
      "BLEU sorces: 7.3576\n",
      "\n",
      "eval: bucket 1 loss 81.8719 perplexity 3.60e+35\n",
      "BLEU 1 sorces: 6.3683\n",
      "BLEU 2 sorces: 2.8035\n",
      "BLEU 3 sorces: 1.0817\n",
      "BLEU 4 sorces: 0.0000\n",
      "Q: german !\n",
      "A: of course ! what else do you think they speak here ?\n",
      "G: +++$+++ you ' re the one who ' s gonna be in the _UNK ,\n",
      "BLEU sorces: 6.4900\n",
      "\n",
      "Q: gigglepuss is playing there tomorrow night .\n",
      "A: don ' t make me do it , man\n",
      "G: i ' m not sure you ' re not the only one who ' s\n",
      "BLEU sorces: 5.7046\n",
      "\n",
      "Q: did you know ? had you heard ?\n",
      "A: what ?\n",
      "G: no , i didn ' t say it was the only one of the _UNK\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "eval: bucket 2 loss 120.8757 perplexity 3.13e+52\n",
      "BLEU 1 sorces: 10.8002\n",
      "BLEU 2 sorces: 4.8074\n",
      "BLEU 3 sorces: 2.4656\n",
      "BLEU 4 sorces: 1.2792\n",
      "Q: what ' ve you got for me ?\n",
      "A: i ' ve _UNK certain pieces of information on miss _UNK stratford i think you ' ll find helpful .\n",
      "G: i ' m not sure you ' re not the only one i ' m gonna do , you '\n",
      "BLEU sorces: 25.0000\n",
      "\n",
      "Q: took it out the bathroom window . buried it in the woods .\n",
      "A: show me .\n",
      "G: +++$+++ you ' re the one who ' s gonna be in the middle of the _UNK , you '\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "Q: i almost forgot . that pal of yours from the vice squad wants you to call him .\n",
      "A: what ?\n",
      "G: i ' m not sure you ' re not the only one of the _UNK of the _UNK _UNK .\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "eval: bucket 3 loss 187.6671 perplexity 3.18e+81\n",
      "BLEU 1 sorces: 16.6797\n",
      "BLEU 2 sorces: 7.2762\n",
      "BLEU 3 sorces: 3.9129\n",
      "BLEU 4 sorces: 1.8216\n",
      "Q: look , we can help you but right now we have to deal with what ' s happening here . tell us the truth . . . is that the truth ?\n",
      "A: you ' re a cop - you ' ll never believe me .\n",
      "G: +++$+++ i ' m not sure you ' re not the only one of the _UNK , you ' re\n",
      "BLEU sorces: 22.4479\n",
      "\n",
      "Q: no , not exactly . i ' ll look at the divorce _UNK , see if we can get it _UNK . interview your daughter . jill , right ?\n",
      "A: yes .\n",
      "G: +++$+++ i ' m not sure you ' re not the only one of the _UNK , you ' re\n",
      "BLEU sorces: 0.0000\n",
      "\n",
      "Q: yes , and more than that . . . you must give her the stones , she ' s the only one who knows how to use them .\n",
      "A: . . . so cornelius was telling the truth !\n",
      "G: i ' m not sure you ' re not the only one of the _UNK of the _UNK _UNK .\n",
      "BLEU sorces: 7.3576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    eval(gen_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, movie data is more noise and may need preprocess and much more training. The bot is kind of afraid of make mistake and confused by the noisy data, so it always say: i ' m not sure you ' re not the only one of the _UNK.\n",
    "\n",
    "These dull answer are also needed to be solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
